{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube Data harvesting and Warehousing using SQL,MONGODB and StreamLit\n",
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import json\n",
    "import streamlit as st\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Connection\n",
    "def Api_Key_Connection():\n",
    "    Api_Id =\"AIzaSyBJGs8rTeDlCL6cgvEZaraE6yHptWg5FtA\"\n",
    "\n",
    "    Api_service_name = \"youtube\"\n",
    "    Api_version = \"v3\"\n",
    "    youtube = build(Api_service_name,Api_version,developerKey = Api_Id)\n",
    "    return youtube\n",
    "\n",
    "youtube = Api_Key_Connection()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get channel information\n",
    "def get_channel_info(channel_id):\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "                part = \"snippet,contentDetails,Statistics\",\n",
    "                id = channel_id)\n",
    "            \n",
    "    response1=request.execute()\n",
    "\n",
    "    for i in range(0,len(response1[\"items\"])):\n",
    "        data = dict(\n",
    "                    Channel_Name = response1[\"items\"][i][\"snippet\"][\"title\"],\n",
    "                    Channel_Id = response1[\"items\"][i][\"id\"],\n",
    "                    Subscription_Count= response1[\"items\"][i][\"statistics\"][\"subscriberCount\"],\n",
    "                    Views = response1[\"items\"][i][\"statistics\"][\"viewCount\"],\n",
    "                    Total_Videos = response1[\"items\"][i][\"statistics\"][\"videoCount\"],\n",
    "                    Channel_Description = response1[\"items\"][i][\"snippet\"][\"description\"],\n",
    "                    Playlist_Id = response1[\"items\"][i][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
    "                    )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Playlist ids\n",
    "def get_playlist_info(channel_id):\n",
    "    All_data = []\n",
    "    next_page_token = None\n",
    "    next_page = True\n",
    "    while next_page:\n",
    "\n",
    "        request = youtube.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']: \n",
    "            data={'PlaylistId':item['id'],\n",
    "                  'Title':item['snippet']['title'],\n",
    "                  'ChannelId':item['snippet']['channelId'],\n",
    "                  'ChannelName':item['snippet']['channelTitle'],\n",
    "                   'PublishedAt':item['snippet']['publishedAt'],\n",
    "                   'VideoCount':item['contentDetails']['itemCount']}\n",
    "            All_data.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            next_page=False\n",
    "    return All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_details = get_channel_info(\"UChGd9JY4yMegY6PxqpBjpRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET Video Id\n",
    "def get_video_ids(channel_id):\n",
    " video_ids=[]\n",
    " response=youtube.channels().list(id = channel_id,\n",
    "                                       part =\"contentDetails\").execute()\n",
    " Playlist_Id=response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "\n",
    " next_page_token = None\n",
    "\n",
    "\n",
    " while True:\n",
    "     response1=youtube.playlistItems().list(\n",
    "                                    part =\"snippet\",\n",
    "                                    playlistId=Playlist_Id,\n",
    "                                    maxResults=50,\n",
    "                                    pageToken=next_page_token).execute()\n",
    "     for i in range(len(response1[\"items\"])):                                 \n",
    "       video_ids.append(response1[\"items\"][i][\"snippet\"][\"resourceId\"][\"videoId\"])    \n",
    "     next_page_token=response1.get(\"nextPageToken\")\n",
    "\n",
    "     if next_page_token is None:\n",
    "        break\n",
    " return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Ids=get_video_ids(\"UChGd9JY4yMegY6PxqpBjpRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Video Information  \n",
    "def get_video_info(video_ids):\n",
    "    video_data = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,ContentDetails,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            data = dict(\n",
    "               Channel_Name=item['snippet']['channelTitle'],\n",
    "               Channel_Id=item['snippet']['channelId'],\n",
    "               Video_ID=item['id'],\n",
    "               Title=item['snippet']['title'],\n",
    "               Tags=item['snippet'].get('tags',['na']),\n",
    "               Thumbnail=item['snippet']['thumbnails']['default']['url'],\n",
    "               Description=item['snippet'].get('description',['na']),\n",
    "               Published_Date=item['snippet']['publishedAt'],\n",
    "               Duration=item['contentDetails']['duration'],\n",
    "               Views=item['statistics'].get('viewCount',0),\n",
    "               Likes = item['statistics'].get('likeCount',0),\n",
    "               Comments=item['statistics'].get('commentCount',0),\n",
    "               Favorite_Count=item['statistics']['favoriteCount'],\n",
    "               Definition=item['contentDetails']['definition'],\n",
    "               Caption_status=item['contentDetails']['caption']\n",
    "            )\n",
    "            video_data.append(data)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details = get_video_info(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Comment Information\n",
    "def get_Comment_information(video_ids):\n",
    "    Comment_data = []\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=50\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response[\"items\"]:\n",
    "                data = dict(\n",
    "                    Comment_id=item['snippet']['topLevelComment']['id'],\n",
    "                    Video_Id=item['snippet']['topLevelComment']['snippet']['videoId'],\n",
    "                    Comment_Text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                    Comment_Author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                    Comment_Published_date=item['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                    LikeCount=item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "                )\n",
    "                Comment_data.append(data)\n",
    "    except:\n",
    "         pass\n",
    "    return Comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_details = get_Comment_information(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB Connection Establishment\n",
    "client = pymongo.MongoClient(\"mongodb+srv://ramanaathan1:rAMANAA5882@cluster0.mzvob39.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db=client[\"Youtube_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to MongoDB\n",
    "def channel_details(channel_id):\n",
    "    ch_details=get_channel_info(channel_id)\n",
    "    pl_details=get_playlist_info(channel_id)\n",
    "    vi_ids=get_video_ids(channel_id)\n",
    "    vi_details=get_video_info(vi_ids)\n",
    "    comm_details=get_Comment_information(vi_ids)\n",
    "\n",
    "    collec1=db[\"channel_details\"]\n",
    "    collec1.insert_one({\"channel_information\":ch_details,\"playlist_information\":pl_details,\"video_information\":vi_details,\"comment_information\":comm_details})\n",
    "\n",
    "    return \"Upload Completed Successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert=channel_details(\"UC5cY198GU1MQMIPJgMkCJ_Q\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert\n",
    "\n",
    "#Pawan Lalwani         \"UC5fs7PookxGfDPTo-RU0ReQ\"\n",
    "#Mr Gk                 \"UC5cY198GU1MQMIPJgMkCJ_Q\"\n",
    "#Data Science in tamil \"UCTCMjShTpZg96cXloCO9q1w\"\n",
    "#ScientificThamizhans  \"UCfbWU8xoxvzDSTQsqLNnVog\"\n",
    "#Mr T pokemon          \"UCU3wULlj7uCYKjZ32lbtazQ\"\n",
    "#Guri Bolte            \"UC7XZytvp1zBEMvnHm5lmwOA\"\n",
    "#Shridhar V            \"UCKQeGTsgUcO8eFoeSD-39rw\"\n",
    "#TanyaKhanijow         \"UCGeGhS_akOxBWQcSmje6B-w\"\n",
    "#KingsleyMusicLessons  \"UCv0kbxb0quwSawbx6nQekdg\"\n",
    "#electrophoenixzara    \"UC2TcWTdvMIcuSbHIJMHjPRA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Creation of channel:\n",
    "def channels_table():\n",
    "   # PostgreSQL connection\n",
    "   mydb = psycopg2.connect(host=\"localhost\",\n",
    "                            user=\"postgres\",\n",
    "                            password=\"onssnm1972\",\n",
    "                            database=\"Youtube_data\",\n",
    "                            port=\"5432\")\n",
    "   cursor = mydb.cursor()\n",
    "   \n",
    "   # Drop existing table\n",
    "   drop_query = '''DROP TABLE IF EXISTS CHANNELS'''\n",
    "   cursor.execute(drop_query)\n",
    "   mydb.commit()\n",
    "   \n",
    "   # Create new table\n",
    "   create_query = '''CREATE TABLE IF NOT EXISTS CHANNELS (Channel_Name VARCHAR(100),\n",
    "                                                          Channel_Id VARCHAR(80) PRIMARY KEY,\n",
    "                                                          Subscription_Count BIGINT,\n",
    "                                                          Views  BIGINT,\n",
    "                                                          Total_Videos INT ,\n",
    "                                                          Channel_Description Text ,\n",
    "                                                          Playlist_Id varchar(50)\n",
    "                                                            )'''\n",
    "   cursor.execute(create_query)\n",
    "   mydb.commit()\n",
    "       \n",
    "   # MongoDB connection\n",
    "   db = client[\"Youtube_data\"]\n",
    "   colle1 = db[\"channel_details\"]\n",
    "\n",
    "   # Retrieve data from MongoDB\n",
    "   cl_list=[]\n",
    "   db = client[\"Youtube_data\"]\n",
    "   colle1 = db[\"channel_details\"]\n",
    "   for cl_data in colle1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
    "        cl_list.append(cl_data[\"channel_information\"])\n",
    "   df = pd.DataFrame(cl_list)\n",
    "\n",
    "   # Insert values into PostgreSQL table\n",
    "   for index, row in df.iterrows():\n",
    "      insert_query = '''insert into channels (Channel_Name,\n",
    "                                              Channel_Id,\n",
    "                                              Subscription_Count,\n",
    "                                              Views,\n",
    "                                              Total_Videos,\n",
    "                                              Channel_Description,\n",
    "                                              Playlist_Id\n",
    "                                                )\n",
    "                                                VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "      values = (\n",
    "            row['Channel_Name'],\n",
    "            row['Channel_Id'],\n",
    "            row['Subscription_Count'],\n",
    "            row['Views'],\n",
    "            row['Total_Videos'],\n",
    "            row['Channel_Description'],\n",
    "            row['Playlist_Id']\n",
    "        )\n",
    "      try:\n",
    "       cursor.execute(insert_query, values)\n",
    "       mydb.commit()\n",
    "       \n",
    "      except:\n",
    "         st.write(\"channels values are inserted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create playlist table\n",
    "def playlists_table():\n",
    "    # PostgreSQL connection\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"onssnm1972\",\n",
    "        database=\"Youtube_data\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # Drop existing table\n",
    "    drop_query = '''DROP TABLE IF EXISTS PLAYLISTS'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    # Create new table\n",
    "    try:\n",
    "        create_query ='''CREATE TABLE IF NOT EXISTS PLAYLISTS (\n",
    "                        PlaylistId\t VARCHAR(100) PRIMARY KEY,\n",
    "                        Title VARCHAR(100),\n",
    "                        ChannelId VARCHAR(100),\n",
    "                        ChannelName VARCHAR(100),\n",
    "                        PublishedAt TIMESTAMP,\n",
    "                        VideoCount INT\n",
    "                    )'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "\n",
    "    except:\n",
    "        st.write(\"playlist table already created\")\n",
    "\n",
    "\n",
    "    # MongoDB connection\n",
    "    db = client[\"Youtube_data\"]\n",
    "    colle1 = db[\"channel_details\"]\n",
    "\n",
    "    # Retrieve data from MongoDB\n",
    "    pl_list = []\n",
    "    for pl_data in colle1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df1 = pd.DataFrame(pl_list)\n",
    "\n",
    "    # Insert values into PostgreSQL table\n",
    "    for index, row in df1.iterrows():\n",
    "        insert_query = '''insert into playlists (\n",
    "                            PlaylistId\t,\n",
    "                            Title,\n",
    "                            ChannelId,\n",
    "                            ChannelName,\n",
    "                            PublishedAt,\n",
    "                            VideoCount\n",
    "                        )\n",
    "                        VALUES(%s,%s,%s,%s,%s,%s)'''\n",
    "        values = (\n",
    "            row['PlaylistId'],\n",
    "            row['Title'],\n",
    "            row['ChannelId'],\n",
    "            row['ChannelName'],\n",
    "            row['PublishedAt'],\n",
    "            row['VideoCount']\n",
    "        )\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except:\n",
    "            st.write(\"playlist table values are inserted\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create videos table\n",
    "def videos_table():\n",
    "\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"onssnm1972\",\n",
    "                database= \"Youtube_data\",\n",
    "                port = \"5432\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists videos\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists videos(\n",
    "                        Channel_Name varchar(150),\n",
    "                        Channel_Id varchar(100),\n",
    "                        Video_ID varchar(50) primary key, \n",
    "                        Title varchar(150), \n",
    "                        Tags text,\n",
    "                        Thumbnail varchar(225),\n",
    "                        Description text, \n",
    "                        Published_Date timestamp,\n",
    "                        Duration interval, \n",
    "                        Views bigint, \n",
    "                        Likes bigint,\n",
    "                        Comments int,\n",
    "                        Favorite_Count int, \n",
    "                        Definition varchar(10), \n",
    "                        Caption_status varchar(50) \n",
    "                        )''' \n",
    "                        \n",
    "        cursor.execute(create_query)             \n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Videos Table already created\")\n",
    "\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    colle1 = db[\"channel_details\"]\n",
    "    for vi_data in colle1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    df2 = pd.DataFrame(vi_list)\n",
    "        \n",
    "    \n",
    "    for index, row in df2.iterrows():\n",
    "        insert_query = '''\n",
    "                    INSERT INTO videos (Channel_Name,\n",
    "                                        Channel_Id,\n",
    "                                        Video_ID, \n",
    "                                        Title, \n",
    "                                        Tags,\n",
    "                                        Thumbnail,\n",
    "                                        Description, \n",
    "                                        Published_Date,\n",
    "                                        Duration, \n",
    "                                        Views, \n",
    "                                        Likes,\n",
    "                                        Comments,\n",
    "                                        Favorite_Count, \n",
    "                                        Definition, \n",
    "                                        Caption_status \n",
    "                                      )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\n",
    "                '''\n",
    "        values = (\n",
    "                    row['Channel_Name'],\n",
    "                    row['Channel_Id'],\n",
    "                    row['Video_ID'],\n",
    "                    row['Title'],\n",
    "                    row['Tags'],\n",
    "                    row['Thumbnail'],\n",
    "                    row['Description'],\n",
    "                    row['Published_Date'],\n",
    "                    row['Duration'],\n",
    "                    row['Views'],\n",
    "                    row['Likes'],\n",
    "                    row['Comments'],\n",
    "                    row['Favorite_Count'],\n",
    "                    row['Definition'],\n",
    "                    row['Caption_status'])\n",
    "                                \n",
    "        try:    \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "        except:\n",
    "            st.write(\"videos values  inserted in the table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create comment table\n",
    "def comment_table():\n",
    "    # PostgreSQL connection\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"onssnm1972\",\n",
    "        database=\"Youtube_data\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # Drop existing table\n",
    "    drop_query = '''DROP TABLE IF EXISTS COMMENTS'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    # Create new table\n",
    "    create_query = '''CREATE TABLE IF NOT EXISTS COMMENTS (\n",
    "        Comment_id VARCHAR(100) PRIMARY KEY,\n",
    "        Video_Id VARCHAR(50),\n",
    "        Comment_Text TEXT,\n",
    "        Comment_Author VARCHAR(150),\n",
    "        Comment_Published_date TIMESTAMP,\n",
    "        LikeCount INT\n",
    "    )'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "     # MongoDB connection\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collec1 = db[\"channel_details\"]\n",
    "\n",
    "    # Retrieve data from MongoDB\n",
    "    com_list = []\n",
    "    for com_data in collec1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
    "        for i in range(len(com_data[\"comment_information\"])):\n",
    "            com_list.append(com_data[\"comment_information\"][i])\n",
    "\n",
    "    # Create DataFrame from MongoDB data\n",
    "    df3 = pd.DataFrame(com_list)\n",
    "\n",
    "    # Insert values into PostgreSQL table\n",
    "    for index, row in df3.iterrows():\n",
    "        insert_query = '''\n",
    "            INSERT INTO comments (\n",
    "                             Comment_id, \n",
    "                             Video_Id,\n",
    "                             Comment_Text,\n",
    "                             Comment_Author,\n",
    "                             Comment_Published_date,\n",
    "                             LikeCount\n",
    "                           )\n",
    "                           VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                       '''\n",
    "        values = (\n",
    "            row['Comment_id'],\n",
    "            row['Video_Id'],\n",
    "            row['Comment_Text'],\n",
    "            row['Comment_Author'],\n",
    "            row['Comment_Published_date'],\n",
    "            row['LikeCount']\n",
    "        )\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except:\n",
    "            st.write(\"comment values are inserted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_tables():\n",
    "    channels_table()\n",
    "    playlists_table()\n",
    "    videos_table()\n",
    "    comment_table()\n",
    "\n",
    "    return \"Tables created successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table = all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "  cl_list=[]\n",
    "  db = client[\"Youtube_data\"]\n",
    "  colle1 = db[\"channel_details\"]\n",
    "  for cl_data in colle1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
    "      cl_list.append(cl_data[\"channel_information\"])\n",
    "  df = st.dataframe(cl_list)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "  pl_list = []\n",
    "  db = client[\"Youtube_data\"]\n",
    "  colle1 = db[\"channel_details\"]\n",
    "  for pl_data in colle1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
    "      for i in range(len(pl_data[\"playlist_information\"])):\n",
    "        pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "  df1 = st.dataframe(pl_list)\n",
    "\n",
    "  return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "  vi_list = []\n",
    "  db = client[\"Youtube_data\"]\n",
    "  collec1 = db[\"channel_details\"]\n",
    "  for vi_data in collec1.find({}, {\"_id\": 0, \"video_information\": 1}):\n",
    "      for i in range(len(vi_data[\"video_information\"])):\n",
    "        vi_list.append(vi_data[\"video_information\"][i])\n",
    "  df2 = st.dataframe(vi_list)\n",
    "\n",
    "  return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "  com_list = []\n",
    "  db = client[\"Youtube_data\"]\n",
    "  collec1 = db[\"channel_details\"]\n",
    "  for com_data in collec1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
    "      for i in range(len(com_data[\"comment_information\"])):\n",
    "         com_list.append(com_data[\"comment_information\"][i])\n",
    "  df3 = st.dataframe(com_list)\n",
    "\n",
    "  return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit \n",
    "with st.sidebar:\n",
    "   st.title(\":Bossanova[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "   st.header(\"CONTENTS\")\n",
    "   st.caption(\"PYTHON  SCRIPTING\")\n",
    "   st.caption(\"DATA COLLECTION\")\n",
    "   st.caption(\"MONGODB\")\n",
    "   st.caption(\"API INTEGRATION\")\n",
    "   st.caption(\"DATA MANAGEMENT USING MONGODB AND POSTGRESQL\")\n",
    "\n",
    "channel_id=st.text_input(\"ENTER THE CHANNEL ID\")\n",
    "\n",
    "if st.button(\"collect and store data\"):\n",
    "   ch_ids=[]\n",
    "   db=client[\"Youtube_data\"]\n",
    "   collec1=db[\"channel_details\"]\n",
    "   for ch_data in collec1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "       ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
    "   \n",
    "   if channel_id in ch_ids:\n",
    "      st.success(\"CHANNEL DETAILS OF THE GIVEN CHANNEL ID ALREADY EXISTS \")\n",
    "   else:\n",
    "      insert=channel_details(channel_id)\n",
    "      st.success(insert)\n",
    "\n",
    "\n",
    "if st.button(\"MIGRATE TO POSTGRESQL\"):\n",
    "   Table = all_tables()\n",
    "   st.success(Table)\n",
    "\n",
    "# Show output as dataframes in streamlit\n",
    "show_table = st.radio(\"SELECT THE TABLE FOR VIEW\",(\"CHANNELS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
    "\n",
    "if show_table ==\"CHANNELS\":\n",
    "   show_channels_table()\n",
    "\n",
    "elif show_table ==\"PLAYLISTS\":\n",
    "   show_playlists_table()\n",
    "\n",
    "elif show_table == \"VIDEO\":\n",
    "   show_videos_table()\n",
    "\n",
    "elif show_table ==\"COMMENTS\":\n",
    "   show_comments_table()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection\n",
    "mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"onssnm1972\",\n",
    "        database=\"Youtube_data\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "\n",
    "\n",
    "Question = st.selectbox(\"SELECT YOUR QUESTION\",(\"1.ALL THE VIDEOS AND THEIR CORRESPONDING CHANNELS NAME\",\n",
    "                                                \"2.CHANNELS WITH  MOST NUMBER OF VIDEOS\",\n",
    "                                                \"3.TOP 10 MOST VIEWED VIDEOS\",\n",
    "                                                \"4.COMMENTS IN EACH VIDEOS\",\n",
    "                                                \"5.VIDEOS WITH HIGHEST LIKES\",\n",
    "                                                \"6.LIKES OF ALL VIDEOS\",\n",
    "                                                \"7.VIEWS OF EACH CHANNEL\",\n",
    "                                                \"8.VIDEOS PUBLISHED IN THE YEAR OF 2022\",\n",
    "                                                \"9.AVERAGE DURATION OF ALL VIDEOS IN EACH CHANNEL\",\n",
    "                                                \"10.VIDEOS WITH HIGHEST NUMBER OF COMMENTS\" ))\n",
    "\n",
    "\n",
    "if Question == '1. All the videos and the Channel Name':\n",
    "   query1 ='''select title as videos,channel_name as channelname from videos '''\n",
    "   cursor.execute(query1)\n",
    "   mydb.commit()\n",
    "   ta1=cursor.fetchall()\n",
    "   df1=pd.DataFrame(ta1,columns=[\"VIDEO TITLE\",\"CHANNEL NAME\"])\n",
    "   st.write(df1)\n",
    "\n",
    "elif Question == '2. Channels with most number of videos':\n",
    "   query2 ='''select channel_name as channelname,total_videos as no_videos from channels \n",
    "           order by total_videos desc'''\n",
    "   cursor.execute(query2)\n",
    "   mydb.commit()\n",
    "   ta2=cursor.fetchall()\n",
    "   df2=pd.DataFrame(ta2,columns=[\"CHANNEL NAME\",\"NO OF VIDEOS\"])\n",
    "   st.write(df2)\n",
    "\n",
    "elif Question == '3. 10 most viewed videos':\n",
    "    query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos \n",
    "                        where Views is not null order by Views desc limit 10;'''\n",
    "    cursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    ta3 = cursor.fetchall()\n",
    "    df3=pd.DataFrame(ta3, columns = [\"VIEWS\",\"CHANNEL NAME\",\"VIDEO TITLE\"])\n",
    "    st.write(df3)\n",
    "\n",
    "elif Question == '4. Comments in each video':\n",
    "    query4 = \"select Comments as No_comments ,Title as VideoTitle from videos where Comments is not null;\"\n",
    "    cursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    ta4=cursor.fetchall()\n",
    "    df4=pd.DataFrame(ta4, columns=[\"No Of Comments\", \"Video Title\"])\n",
    "    st.write(df4)\n",
    "\n",
    "elif Question == '5. Videos with highest likes':\n",
    "    query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                       where Likes is not null order by Likes desc;'''\n",
    "    cursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    ta5 = cursor.fetchall()\n",
    "    df5=pd.DataFrame(ta5, columns=[\"video Title\",\"channel Name\",\"like count\"])\n",
    "    st.write(df5)\n",
    "\n",
    "elif Question == '6. likes of all videos':\n",
    "    query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "    cursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    ta6 = cursor.fetchall()\n",
    "    df6=pd.DataFrame(ta6, columns=[\"like count\",\"video title\"])\n",
    "    st.write(df6)\n",
    "\n",
    "elif Question == '7. views of each channel':\n",
    "    query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
    "    cursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    ta7=cursor.fetchall()\n",
    "    df7=pd.DataFrame(ta7, columns=[\"channel name\",\"total views\"])\n",
    "    st.write(df7)\n",
    "\n",
    "elif Question == '8. videos published in the year 2022':\n",
    "    query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                where extract(year from Published_Date) = 2022;'''\n",
    "    cursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    ta8=cursor.fetchall()\n",
    "    df8= pd.DataFrame(ta8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"])\n",
    "    st.write(df8)\n",
    "\n",
    "elif Question == '9. average duration of all videos in each channel':\n",
    "    query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
    "    cursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    ta9=cursor.fetchall()\n",
    "    ta9 = pd.DataFrame(ta9, columns=['ChannelTitle', 'Average Duration'])\n",
    "    Ta9=[]\n",
    "    for index, row in ta9.iterrows():\n",
    "        channel_title = row['ChannelTitle']\n",
    "        average_duration = row['Average Duration']\n",
    "        average_duration_str = str(average_duration)\n",
    "        Ta9.append({\"Channel Title\": channel_title ,  \"Average Duration\": average_duration_str})\n",
    "    df9=pd.DataFrame(Ta9)\n",
    "    st.write(df9)\n",
    "\n",
    "elif Question == '10. videos with highest number of comments':\n",
    "    query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "    cursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=cursor.fetchall()\n",
    "    df10= pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments'])\n",
    "    st.write(df10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "cursor.execute(query10)\n",
    "mydb.commit()\n",
    "ta10=cursor.fetchall()\n",
    "df10= pd.DataFrame(ta10, columns=['VIDEO TITLE', 'CHANNEL NAME', 'NO OF COMMENTS'])\n",
    "st.write(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
